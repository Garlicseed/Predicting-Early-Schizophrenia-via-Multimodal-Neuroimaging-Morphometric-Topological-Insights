{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e38811a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.metrics import accuracy_score\n",
    "from itertools import cycle\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Load demo data\n",
    "\n",
    "data_dir = '/media/garlicseed/data2/Schizophrenia'\n",
    "data = pd.read_csv(f'{data_dir}/train.tsv',sep='\\t')\n",
    "\n",
    "# Load graph measures (example of loading one, repeat for others)\n",
    "\n",
    "g1 = pd.read_pickle(f'{data_dir}/feature_train/G1_feature.pkl')\n",
    "g2 = pd.read_pickle(f'{data_dir}/feature_train/G2_feature.pkl')\n",
    "GV = pd.read_pickle(f'{data_dir}/feature_train/GV_feature.pkl')\n",
    "Curv = pd.read_pickle(f'{data_dir}/feature_train/Gaussian_Curvature_feature.pkl')\n",
    "Thickness = pd.read_pickle(f'{data_dir}/feature_train/Thickness_feature.pkl')\n",
    "GD = pd.read_pickle(f'{data_dir}/feature_train/Geodesic_distance_feature.pkl') \n",
    "\n",
    "# Stack the topo measures\n",
    "comprehensive_measures = pd.concat([g1, g2,GV,Curv,Thickness,GD], axis=1)\n",
    "# Combine with demo data\n",
    "#features = pd.concat([data[['group']], topo_measures], axis=1)\n",
    "annot = pd.read_csv(f\"/media/garlicseed/data2/Schizophrenia/integration/material/schaefer_400_label.csv\")\n",
    "\n",
    "# 替换\"7Networks_\"前缀\n",
    "annot['StructName'] = annot['StructName'].str.replace(\"7Networks_\", \"\", regex=False)\n",
    "\n",
    "# 进一步替换具体的字符\n",
    "annot['StructName'] = annot['StructName'].replace({\n",
    "    'LH_': 'L_', 'RH_': 'R_', 'DorsAttn': 'DA', 'Default': 'DF', 'SalVentAttn': 'SVA',\n",
    "    'Limbic': 'LB', 'Cont': 'CON', 'SomMot': 'SM', 'Vis': 'VS'\n",
    "}, regex=True)\n",
    "roi_labels = annot['StructName'].values\n",
    "\n",
    "# Prepare model matrix\n",
    "X = comprehensive_measures\n",
    "\n",
    "#处理索引\n",
    "region_labels = X.columns.get_level_values('Region_Label')\n",
    "networks = X.columns.get_level_values('Network')\n",
    "modalities = X.columns.get_level_values('Modality')\n",
    "types = X.columns.get_level_values('label')\n",
    "region_x = X.columns.get_level_values('region')\n",
    "column_info = {\n",
    "    'region_labels': region_labels,\n",
    "    'networks': networks,\n",
    "    'modalities': modalities,\n",
    "    'types':types,\n",
    "    'regions':region_x\n",
    "}\n",
    "X.columns = region_labels\n",
    "\n",
    "y1 = data['diagnosis'].astype('category')\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "# Split data into train/test\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.pipeline import Pipeline\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(y1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=3, stratify=y)\n",
    "scaler = StandardScaler()\n",
    "encoder = LabelEncoder()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "X_test_scaled = scaler.fit_transform(X_test)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e790237",
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid_search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# 模型字典\n",
    "models_dict = {\n",
    "    \"RandomForest\": Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('classifier', RandomForestClassifier(random_state=42, class_weight= 'balanced_subsample', n_jobs= -1))\n",
    "    ]),\n",
    "    \"GradientBoosting\": Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('classifier', GradientBoostingClassifier(random_state=42, ))\n",
    "    ]),\n",
    "    \"LightGBM\": Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('classifier', LGBMClassifier(random_state=42, verbose=-1, n_jobs= -1, colsample_bylevel = 0.6, subsample = 0.7))\n",
    "    ]),\n",
    "    \"CatBoost\": Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('classifier', CatBoostClassifier(verbose=0, random_state=42, thread_count = -1, colsample_bylevel= 0.6, subsample = 0.7))\n",
    "    ]),\n",
    "    \"SVM\": Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('classifier', SVC(probability=True, class_weight='balanced', random_state=42))\n",
    "    ])\n",
    "}\n",
    "\n",
    "# 超参数网格\n",
    "param_grids = {\n",
    "    \"RandomForest\": {\n",
    "        'classifier__n_estimators': [50, 100, 200],\n",
    "        'classifier__max_depth': [None,3, 5, 10, 20, 30],\n",
    "        'classifier__min_samples_split': [2, 5, 10],\n",
    "        'classifier__min_samples_leaf': [1, 2, 4],\n",
    "        'classifier__max_features': ['sqrt', 'log2',None]\n",
    "    },\n",
    "    \"GradientBoosting\": {\n",
    "        'classifier__n_estimators': [50, 100, 200],\n",
    "        'classifier__learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "        'classifier__max_depth': [3, 5, 7],\n",
    "        'classifier__subsample': [0.8, 1.0]\n",
    "    },\n",
    "    \"LightGBM\": {\n",
    "        'classifier__n_estimators': [50, 100, 200, 300],\n",
    "        'classifier__learning_rate': [0.01, 0.1, 0.2],\n",
    "       'classifier__max_depth': [-1, 10, 20],\n",
    "        'classifier__num_leaves': [31, 50, 100]\n",
    "    },\n",
    "    \"CatBoost\": {\n",
    "        'classifier__iterations': [100, 200, 500],\n",
    "        'classifier__learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "        'classifier__depth': [3, 6, 10]\n",
    "    },\n",
    "    \"SVM\": {\n",
    "        'classifier__C': [0.001, 0.01, 0.1, 1],\n",
    "        'classifier__gamma': [0.0001, 0.001, 0.01, 0.1],\n",
    "        'classifier__kernel': ['linear', 'rbf']\n",
    "    }\n",
    "}\n",
    "\n",
    "# 创建 GridSearchCV 对象\n",
    "gridsearch_dict = {}\n",
    "\n",
    "for model_name, pipeline in models_dict.items():\n",
    "    print(f\"Creating GridSearchCV for {model_name}...\")\n",
    "    param_grid = param_grids[model_name]\n",
    "    gridsearch = GridSearchCV(\n",
    "        estimator=pipeline,\n",
    "        param_grid=param_grid,\n",
    "        cv=10,\n",
    "        scoring='accuracy',\n",
    "        verbose=1,\n",
    "        n_jobs=20\n",
    "    )\n",
    "    gridsearch_dict[f\"{model_name}_gridsearch\"] = gridsearch\n",
    "    \n",
    "for model_name, gridsearch in gridsearch_dict.items():\n",
    "    print(f\"Training {model_name}...\")\n",
    "    gridsearch.fit(X_train_scaled, y_train)  # 替换 X_train_scaled 和 y_train 为您的训练集\n",
    "    print(f\"Best parameters for {model_name}: {gridsearch.best_params_}\")\n",
    "    print(f\"Best accuracy for {model_name}: {gridsearch.best_score_}\")\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
